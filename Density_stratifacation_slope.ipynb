{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c53deeb7-9609-489d-958d-482e1afcca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import glob\n",
    "from cmip6_preprocessing.preprocessing import combined_preprocessing\n",
    "import cftime\n",
    "from datetime import datetime\n",
    "xr.set_options(display_style='html')\n",
    "plt.rcParams['figure.figsize'] = 8,3\n",
    "\n",
    "import gsw as gs\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7800527-e8ed-43fe-942c-96cf281445bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    return lst3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5465f50-1109-42c5-a207-debc2af9ad63",
   "metadata": {},
   "source": [
    "We calculate density, buoyancy frequency, and isopycnal slope from T and S.\n",
    "Below uses the paths where my data are and checks to make sure we have a list of models for which I have T and S data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9405ea2-633f-4295-9711-920311936edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/gws/nopw/j04/ukfafmip/users/enewsom/regrid_from_jonathan_thetoa/cmip6/CONCATTED/'\n",
    "data_dir_so = '/gws/nopw/j04/ukfafmip/users/enewsom/regrid_from_jonathan_so/cmip6/'\n",
    "\n",
    "\n",
    "files_c6 =  glob.glob(data_dir+ 'thetao_Oyr_*_piControl*.nc')\n",
    "files_so_c6 =  glob.glob(data_dir_so+ 'so_Oyr_*_piControl*.nc')\n",
    "\n",
    "\n",
    "models=[]\n",
    "for file in files_c6:\n",
    "    model = file.split(\"_\")[5]\n",
    "    models.append(model)\n",
    "MODELS=np.unique(models)\n",
    "\n",
    "\n",
    "models=[]\n",
    "for file in files_so_c6:\n",
    "    model = file.split(\"_\")[5]\n",
    "    models.append(model)\n",
    "MODELS2=np.unique(models)\n",
    " \n",
    "MODELS_do_c6 = intersection(MODELS, MODELS2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dffffc50-3541-48ea-bb0a-1831049d63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/gws/nopw/j04/ukfafmip/users/enewsom/regrid_from_jonathan_thetoa/cmip5/CONCATTED/'\n",
    "data_dir_so = '/gws/nopw/j04/ukfafmip/users/enewsom/regrid_from_jonathan_so/cmip5/'\n",
    "\n",
    "files_c5 =  glob.glob(data_dir+ 'thetao_*yr_*_piControl*.nc')\n",
    "files_so_c5 =  glob.glob(data_dir_so+ 'so_*yr_*_piControl*.nc')\n",
    "\n",
    "models=[]\n",
    "for file in files_c5:\n",
    "    model = file.split(\"_\")[5]\n",
    "    models.append(model)\n",
    "MODELS=np.unique(models)\n",
    "\n",
    "\n",
    "models=[]\n",
    "for file in files_so_c5:\n",
    "    model = file.split(\"_\")[5]\n",
    "    models.append(model)\n",
    "MODELS2=np.unique(models)\n",
    "\n",
    "MODELS_do_c5 = intersection(MODELS, MODELS2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17abaf38-6256-452d-b985-3bf722f8d0ba",
   "metadata": {},
   "source": [
    "Below chooses a random model (CESM2) to grab a z-grid to interpolate to and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c4fb27c-0e22-403d-93b6-03b14cc87ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/gws/nopw/j04/ukfafmip/users/enewsom/regrid_from_jonathan_thetoa/cmip6/CONCATTED/thetao_Oyr_CESM2_piControl_r1i1p1f1_gn_regridded_050001-059912.nc'\n",
    "\n",
    "dc  = xr.open_dataset(file).assign_attrs(source_id='CESM2')\n",
    "dc=combined_preprocessing(dc)\n",
    "Tc= dc['thetao']\n",
    "Tc = Tc.isel(time = slice(40,80)).mean('time')\n",
    "if Tc.dims[0]!='lev':\n",
    "    Tc = Tc.rename({Tc.dims[0]:'lev'})   \n",
    "TcX=Tc.assign_coords(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0350ba1e-2ba7-4962-9a9d-cfe6fef6c300",
   "metadata": {},
   "source": [
    "Next calculate metrics salinity, density, N$^2$ (called \"stratification\"), or $\\frac{\\partial\\sigma_2}{\\partial y}$ and $\\frac{\\partial\\sigma_2}{\\partial z}$ for isopycal slope <br>\n",
    "Below could be written as a loop over each metric, but it was long for a notebook and I liked using it interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a726de-3393-48e8-88fc-d49d05a42887",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=2000\n",
    "averaging_period_start=0\n",
    "averaging_period_end=80\n",
    "g=9.8\n",
    "rho_0 = 1028\n",
    "lat_to_meters = 1/(111*1000)\n",
    "\n",
    "\n",
    "density = 0\n",
    "stratification = 1\n",
    "slopes = 0\n",
    "\n",
    "cmip6=0\n",
    "cmip5=1\n",
    "\n",
    "if cmip6:\n",
    "    MODELS_do = MODELS_do_c6\n",
    "    files = files_c6\n",
    "    files_so = files_so_c6\n",
    "    ens = 'cmip6'\n",
    "else:\n",
    "    MODELS_do = MODELS_do_c5\n",
    "    files = files_c5\n",
    "    files_so = files_so_c5\n",
    "    ens='cmip5'\n",
    "\n",
    "\n",
    "S=[]\n",
    "ST=[]\n",
    "SZ=[]\n",
    "SY=[]\n",
    "PX=[]\n",
    "\n",
    "for count,model in enumerate(MODELS_do):\n",
    "    print(model)\n",
    "    \n",
    "    files_c = [match for match in files if model in match]\n",
    "    files_s = [match for match in files_so if model in match]\n",
    "           \n",
    "    file = files_c[0]\n",
    "    file_s = files_s[0]\n",
    "    \n",
    "    dc  = xr.open_dataset(file).assign_attrs(source_id=model)\n",
    "    dc=combined_preprocessing(dc)\n",
    "    variable = list(dc.keys())[-1] #grab variable name for temp (not all the same)\n",
    "    Tc= dc[variable].rename('thetao')#rename to the same variable name in data array\n",
    "    Tc = Tc.isel(time = slice(averaging_period_start,averaging_period_end)).mean('time')\n",
    "    Tc=Tc.where(np.abs(Tc)<1e3) #here I mask where some models have weird fill values\n",
    "    Tc = Tc.rename({Tc.dims[0]:'lev'}) #here is because not all models have the same vertical coord name\n",
    "    Tcx=Tc.assign_coords(model=model)\n",
    "        \n",
    "    ds  = xr.open_dataset(file_s).assign_attrs(source_id=model)\n",
    "    ds=combined_preprocessing(ds)\n",
    "    Sc= ds['so']\n",
    "    Sc = Sc.isel(time = slice(averaging_period_start,averaging_period_end)).mean('time')\n",
    "    Sc=Sc.where(np.abs(Tc)<1e3)\n",
    "    Sc = Sc.rename({Sc.dims[0]:'lev'}) \n",
    "    Scx=Sc.assign_coords(model=model)\n",
    "        \n",
    " \n",
    "    SA = gs.SA_from_SP(Scx,p,Scx.x,Scx.y)\n",
    "    CT = gs.CT_from_t(SA,Tcx,p)\n",
    "    Pc = gs.density.sigma2(SA,CT)\n",
    "\n",
    "    if stratification: \n",
    "        strat = (g/rho_0)*Pc.differentiate(\"lev\")\n",
    "        strat = strat.assign_coords(model=model)\n",
    "        strat = strat.interp_like(TcX)*TcX/TcX\n",
    "        ST.append(strat)\n",
    "\n",
    "    if slopes:\n",
    "        #slope = drhody/drhodz, but it's smoother to take zonal mean of each first so we save seperately\n",
    "        drhodz = Pc.differentiate(\"lev\")\n",
    "        drhody= Pc.differentiate(\"y\")*lat_to_meters\n",
    "        drhodz = drhodz.assign_coords(model=model)\n",
    "        drhodz = drhodz.interp_like(TcX)*TcX/TcX\n",
    "        drhody = drhody.assign_coords(model=model)\n",
    "        drhody = drhody.interp_like(TcX)*TcX/TcX\n",
    "        SY.append(drhodz)\n",
    "        SZ.append(drhody)\n",
    "\n",
    "    if density:\n",
    "        Pcx = Pc.interp_like(TcX)*TcX/TcX\n",
    "        Pcx = Pcx.assign_coords(model=model)\n",
    "        PX.append(Pcx)\n",
    "  \n",
    "clear_output(wait=True)\n",
    "    \n",
    "    \n",
    "#below,save drho/dx, drho/dz seperately so we can look at the slope in different basins (not ultimately used in paper)\n",
    "if slopes: \n",
    "    drhody_control_model=xr.concat(SY,dim='model',coords='minimal',compat='override')\n",
    "    drhodz_control_model=xr.concat(SZ,dim='model',coords='minimal',compat='override')\n",
    "    drhodz_control_model_sig2.to_netcdf('drhodz_control_model_'+ens+'.nc')\n",
    "    drhody_control_model_sig2.to_netcdf('drhody_control_model_'+ens+'.nc')\n",
    "    drhodz_control_model_sig2.close()\n",
    "    drhody_control_model_sig2.close()\n",
    "    \n",
    "if stratification:\n",
    "    strat_control_model_sig2=xr.concat(ST,dim='model',coords='minimal',compat='override')\n",
    "    strat_control_model_sig2.to_netcdf('strat_control_model_sig2_'+ens+'.nc')\n",
    "    strat_control_model_sig2.close()\n",
    "\n",
    "if density:\n",
    "    Dense_control_model_sig2=xr.concat(PX,dim='model',coords='minimal',compat='override')\n",
    "    Dense_control_model_sig2.to_netcdf('Dense_control_model_sig2_'+ens+'.nc')\n",
    "    Dense_control_model_sig2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672adbdb-9095-4c30-b2ed-56a94077094c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbenv2",
   "language": "python",
   "name": "nbenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
